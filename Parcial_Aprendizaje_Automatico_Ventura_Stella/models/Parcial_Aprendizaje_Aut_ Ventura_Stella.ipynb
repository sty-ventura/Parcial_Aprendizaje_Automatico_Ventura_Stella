{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc5ae84",
   "metadata": {},
   "source": [
    "### Importar las librerias con las que se va trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8144e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000ae2a",
   "metadata": {},
   "source": [
    "### Importar el dataset de remuneraciones (formato XLSX), usando la primera fila √∫til como encabezado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_remuneraciones = os.path.join(\"..\", \"data\", \"raw\", \"21_1_01_Remuneracion-promedio-de-los-trabajadores-registrados-del-sector-privado-segun-rama-de-actividad.xlsx\")\n",
    "df_remuneraciones = pd.read_excel(archivo_remuneraciones, header=2)\n",
    "\n",
    "print(df_remuneraciones.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb1861",
   "metadata": {},
   "source": [
    "### Explorar columnas a utilizar, seleccionarlas y renombrarlas para una manipulaci√≥n m√°s efectiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_remuneraciones.columns.tolist())\n",
    "print(type(df_remuneraciones.columns))\n",
    "\n",
    "# Cambiar el nombre de las columnas para que sean m√°s descriptivas o f√°ciles de usar\n",
    "# Por ejemplo, renombrar las dos primeras columnas y dejar las fechas igual\n",
    "\n",
    "df_remuneraciones = df_remuneraciones.rename(columns={\n",
    "    df_remuneraciones.columns[0]: \"Codigo\",\n",
    "    df_remuneraciones.columns[1]: \"Rama_Actividad\"\n",
    "})\n",
    "\n",
    "print(df_remuneraciones.columns[:10])  # Mostrar los primeros 10 nombres de columnas para verificar\n",
    "\n",
    "# Renombrar las columnas desde \"Rama_Actividad\" en adelante para que tengan formato de fecha YYYY-MM\n",
    "# Primero identificamos el √≠ndice de la columna \"Rama_Actividad\"\n",
    "idx = df_remuneraciones.columns.get_loc(\"Rama_Actividad\")\n",
    "\n",
    "# Las columnas de fechas empiezan en el siguiente √≠ndice\n",
    "fecha_cols = df_remuneraciones.columns[(idx+1):]\n",
    "\n",
    "# Creamos nuevos nombres en formato YYYY-MM\n",
    "nuevos_nombres = {}\n",
    "for col in fecha_cols:\n",
    "    try:\n",
    "        # Intentar convertir el nombre de la columna a formato fecha\n",
    "        fecha = pd.to_datetime(col, format='%Y-%m')\n",
    "        nuevos_nombres[col] = fecha.strftime('%Y-%m')\n",
    "    except Exception:\n",
    "        # Si no se puede convertir, dejar el nombre original\n",
    "        nuevos_nombres[col] = col\n",
    "\n",
    "# Renombrar las columnas en el DataFrame\n",
    "df_remuneraciones = df_remuneraciones.rename(columns=nuevos_nombres)\n",
    "\n",
    "print(df_remuneraciones.columns[idx:idx+10])  # Mostrar los primeros 10 nombres despu√©s de \"Rama_Actividad\"\n",
    "# Seleccionar las columnas \"Codigo\", \"Rama_Actividad\" y desde \"2017-12\" hasta el final\n",
    "cols = df_remuneraciones.columns.tolist()\n",
    "start_idx = cols.index(\"2017-12\")\n",
    "selected_cols = [\"Codigo\", \"Rama_Actividad\"] + cols[start_idx:]\n",
    "df_remuneraciones_sel = df_remuneraciones[selected_cols]\n",
    "print(df_remuneraciones_sel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bcbd8",
   "metadata": {},
   "source": [
    "### Verificar nulos y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a452a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar registros nulos\n",
    "print(\"Cantidad de valores nulos por columna:\")\n",
    "print(df_remuneraciones_sel.isnull().sum())\n",
    "\n",
    "# Verificar registros duplicados\n",
    "duplicados = df_remuneraciones_sel.duplicated()\n",
    "print(f\"\\nCantidad de filas duplicadas: {duplicados.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec0283",
   "metadata": {},
   "source": [
    "### Se verifica en el dataset que los datos nulos corresponden a filas enteras vac√≠as (usadas para como encabezados para separar categor√≠as) se eliminan los registros ya que no inciden en el an√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para corregir errores en el DataFrame, primero identificamos filas no v√°lidas (como las de totales, fuentes o confidencialidad)\n",
    "# Eliminamos filas donde 'Codigo' o 'Rama_Actividad' no sean v√°lidas\n",
    "\n",
    "# Filtrar filas donde 'Codigo' y 'Rama_Actividad' no sean nulos y 'Codigo' no sea 'Total' ni contenga 'Fuente' o 'Dato confidencial'\n",
    "df_remuneraciones_sel_clean = df_remuneraciones_sel[\n",
    "    df_remuneraciones_sel['Codigo'].notnull() &\n",
    "    df_remuneraciones_sel['Rama_Actividad'].notnull() &\n",
    "    (~df_remuneraciones_sel['Codigo'].astype(str).str.contains('Total|Fuente|Dato confidencial', case=False, na=False))\n",
    "].copy()\n",
    "\n",
    "# Resetear el √≠ndice\n",
    "df_remuneraciones_sel_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_remuneraciones_sel_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar el tipo de las columnas a partir de la columna \"2017-12\"\n",
    "cols_fecha = df_remuneraciones_sel_clean.columns[2:]  # columnas desde la primera fecha en adelante\n",
    "\n",
    "# Ver si los nombres de columnas son tipo datetime o string con formato YYYY-MM\n",
    "print(\"Tipos de columnas de fecha:\")\n",
    "for col in cols_fecha[:5]:  # mostramos solo las primeras 5\n",
    "    print(f\"{col} ‚Üí tipo: {type(col)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1c869",
   "metadata": {},
   "source": [
    "### Eliminar la columna \"Codigo\" y luego pivotear para dar formato optimizado para el an√°lisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rem_long = df_remuneraciones_sel_clean.drop(columns=[\"Codigo\"]).melt(\n",
    "    id_vars=[\"Rama_Actividad\"],\n",
    "    var_name=\"Fecha\",\n",
    "    value_name=\"Remuneracion\"\n",
    ")\n",
    "df_rem_long[\"Fecha\"] = pd.to_datetime(df_rem_long[\"Fecha\"], format=\"%Y-%m\")\n",
    "df_rem_long = df_rem_long.dropna(subset=[\"Remuneracion\"])\n",
    "# Ver los valores √∫nicos que hay en la columna Remuneracion\n",
    "print(df_rem_long[\"Remuneracion\"].unique())\n",
    "df_rem_long.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e90db",
   "metadata": {},
   "source": [
    "### Verificar valores no reportados o nulos \" s \", considerados nulos, eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d26a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde la remuneraci√≥n es exactamente igual a \"s\"\n",
    "filas_s = df_rem_long[df_rem_long[\"Remuneracion\"] == \" s \"]\n",
    "\n",
    "# Mostrar cu√°ntas hay\n",
    "print(f\"Cantidad de registros con 's': {len(filas_s)}\")\n",
    "\n",
    "# Visualizar las primeras filas (si hay muchas)\n",
    "display(filas_s.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d787db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de actividades a eliminar (con espacio final)\n",
    "actividades_a_eliminar = [\n",
    "    \" Extracci√≥n de minerales metal√≠feros \",\n",
    "    \" Tabaco \",\n",
    "    \" Confecciones \",\n",
    "    \" Cuero y calzado \",\n",
    "    \" Productos de petr√≥leo \",\n",
    "    \" Otros minerales no met√°licos \"\n",
    "    \" Metales comunes \",\n",
    "    \" Maquinaria de oficina \",\n",
    "    \" Aparatos el√©ctricos \",\n",
    "    \" Instrumentos m√©dicos \",\n",
    "    \" Otros equipo de transporte \"\n",
    "]\n",
    "\n",
    "# Filtrar el DataFrame eliminando las actividades\n",
    "df_rem_long = df_rem_long[~df_rem_long[\"Rama_Actividad\"].isin(actividades_a_eliminar)].copy()\n",
    "\n",
    "# Reiniciar √≠ndice\n",
    "df_rem_long.reset_index(drop=True, inplace=True)\n",
    "df_rem_long.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9574800",
   "metadata": {},
   "source": [
    "### Veamos si podemos avanzar con el EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121988f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver dimensiones del dataframe\n",
    "print(\"Dimensiones del DataFrame:\", df_rem_long.shape)\n",
    "\n",
    "# Ver tipos de datos\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(df_rem_long.dtypes)\n",
    "\n",
    "# Ver rango temporal de las fechas\n",
    "print(\"\\nRango de fechas:\")\n",
    "print(\"Desde:\", df_rem_long[\"Fecha\"].min())\n",
    "print(\"Hasta:\", df_rem_long[\"Fecha\"].max())\n",
    "\n",
    "# Ver cu√°ntas ramas √∫nicas hay\n",
    "print(\"\\nCantidad de ramas de actividad:\", df_rem_long[\"Rama_Actividad\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_rem_long.isnull().sum())\n",
    "\n",
    "# Ver estad√≠sticos b√°sicos (solo para Remuneraci√≥n si es num√©rica)\n",
    "print(\"\\nResumen estad√≠stico:\")\n",
    "print(df_rem_long.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76807c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde la remuneraci√≥n es exactamente igual a \"s\"\n",
    "filas_s = df_rem_long[df_rem_long[\"Remuneracion\"] == \" s \"]\n",
    "\n",
    "# Mostrar cu√°ntas hay\n",
    "print(f\"Cantidad de registros con 's': {len(filas_s)}\")\n",
    "\n",
    "# Visualizar las primeras filas (si hay muchas)\n",
    "display(filas_s.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de actividades a eliminar (con espacio final)\n",
    "actividades_a_eliminar = [\n",
    "    \" Extracci√≥n de minerales metal√≠feros \",\n",
    "    \" Tabaco \",\n",
    "    \" Confecciones \",\n",
    "    \" Cuero y calzado \",\n",
    "    \" Productos de petr√≥leo \",\n",
    "    \" Otros minerales no met√°licos \"\n",
    "    \" Metales comunes \",\n",
    "    \" Maquinaria de oficina \",\n",
    "    \" Aparatos el√©ctricos \",\n",
    "    \" Instrumentos m√©dicos \",\n",
    "    \" Papel \",\n",
    "    \" Captaci√≥n, depuraci√≥n y distribuci√≥n de agua \",\n",
    "     \"Investigaci√≥n y desarrollo \",\n",
    "    \" Otros equipo de transporte \"\n",
    "]\n",
    "\n",
    "# Filtrar el DataFrame eliminando las actividades\n",
    "df_rem_long = df_rem_long[~df_rem_long[\"Rama_Actividad\"].isin(actividades_a_eliminar)].copy()\n",
    "\n",
    "# Reiniciar √≠ndice\n",
    "df_rem_long.reset_index(drop=True, inplace=True)\n",
    "df_rem_long.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec14f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde la remuneraci√≥n es exactamente igual a \"s\"\n",
    "filas_s = df_rem_long[df_rem_long[\"Remuneracion\"] == \" s \"]\n",
    "\n",
    "# Mostrar cu√°ntas hay\n",
    "print(f\"Cantidad de registros con 's': {len(filas_s)}\")\n",
    "\n",
    "# Visualizar las primeras filas (si hay muchas)\n",
    "display(filas_s.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Convertir a string y quitar espacios\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].astype(str).str.strip()\n",
    "\n",
    "# Paso 2: Reemplazar todos los valores 's' (sin importar may√∫scula/min√∫scula)\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].replace(\n",
    "    to_replace=r'(?i)^s$', value=np.nan, regex=True\n",
    ")\n",
    "\n",
    "# Paso 3: Verificar cu√°ntos 's' quedan (deber√≠a dar 0)\n",
    "print(\"Valores 's' restantes:\", df_rem_long[\"Remuneracion\"].str.fullmatch(r's', case=False).sum())\n",
    "\n",
    "# Paso 4: Convertir a float\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3df16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar 's' (con posibles espacios) por NaN y eliminar esas filas\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].astype(str).str.strip()\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].replace(\"s\", np.nan)\n",
    "\n",
    "# Eliminar las filas con valores nulos\n",
    "df_rem_long = df_rem_long.dropna(subset=[\"Remuneracion\"])\n",
    "\n",
    "# Convertir a float\n",
    "df_rem_long[\"Remuneracion\"] = df_rem_long[\"Remuneracion\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde 'Remuneracion' no puede convertirse a n√∫mero\n",
    "no_numericas = df_rem_long[pd.to_numeric(df_rem_long[\"Remuneracion\"], errors=\"coerce\").isna()]\n",
    "\n",
    "# Mostrar la cantidad\n",
    "print(f\"Cantidad de valores no num√©ricos en 'Remuneracion': {len(no_numericas)}\")\n",
    "\n",
    "# Mostrar las filas\n",
    "display(no_numericas)\n",
    "# Eliminar filas donde Remuneracion es NaN\n",
    "df_rem_long = df_rem_long.dropna(subset=[\"Remuneracion\"]).copy()\n",
    "\n",
    "# Verificar que se eliminaron correctamente\n",
    "print(f\"Dimensiones finales del DataFrame: {df_rem_long.shape}\")\n",
    "print(f\"¬øA√∫n quedan NaNs en Remuneracion?: {df_rem_long['Remuneracion'].isna().sum()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que Remuneracion sea tipo float\n",
    "df_rem_long[\"Remuneracion\"] = pd.to_numeric(df_rem_long[\"Remuneracion\"], errors='coerce')\n",
    "\n",
    "# Agregar columna 'A√±o'\n",
    "df_rem_long[\"A√±o\"] = df_rem_long[\"Fecha\"].dt.year\n",
    "\n",
    "# === 1. Gr√°fico de evoluci√≥n promedio por actividad y a√±o (escala log) ===\n",
    "plt.figure(figsize=(14, 8))\n",
    "df_grouped = df_rem_long.groupby([\"A√±o\", \"Rama_Actividad\"])[\"Remuneracion\"].mean().reset_index()\n",
    "sns.lineplot(data=df_grouped, x=\"A√±o\", y=\"Remuneracion\", hue=\"Rama_Actividad\", linewidth=1)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Evoluci√≥n de Remuneraciones por Rama de Actividad (escala log)\", fontsize=14)\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"Remuneraci√≥n Promedio (escala log)\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1, fontsize=\"small\", title=\"Rama de Actividad\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# === 2. Boxplot por a√±o para detectar outliers ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_rem_long, x=\"A√±o\", y=\"Remuneracion\")\n",
    "plt.title(\"Distribuci√≥n de Remuneraciones por A√±o (Detecci√≥n de Outliers)\", fontsize=14)\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"Remuneraci√≥n\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el umbral de outliers (percentil 99)\n",
    "umbral = df_rem_long[\"Remuneracion\"].quantile(0.99)\n",
    "\n",
    "# Filtrar las filas que superan ese umbral\n",
    "outliers = df_rem_long[df_rem_long[\"Remuneracion\"] > umbral]\n",
    "\n",
    "# Contar cu√°ntos hay por rama\n",
    "outliers_por_rama = outliers[\"Rama_Actividad\"].value_counts().reset_index()\n",
    "outliers_por_rama.columns = [\"Rama_Actividad\", \"Cantidad de Outliers\"]\n",
    "\n",
    "# Mostrar\n",
    "print(f\"Umbral de outliers (percentil 99): {umbral:,.0f}\")\n",
    "display(outliers_por_rama)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=outliers, y=\"Rama_Actividad\", order=outliers[\"Rama_Actividad\"].value_counts().index)\n",
    "plt.title(\"Actividades que Generan Outliers en Remuneraci√≥n (percentil 99+)\")\n",
    "plt.xlabel(\"Cantidad de Outliers\")\n",
    "plt.ylabel(\"Rama de Actividad\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d7cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio por actividad\n",
    "promedio_por_rama = (\n",
    "    df_rem_long.groupby(\"Rama_Actividad\")[\"Remuneracion\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Crear gr√°fico de barras horizontales\n",
    "plt.figure(figsize=(12, 14))\n",
    "sns.barplot(x=promedio_por_rama.values, y=promedio_por_rama.index, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Remuneraci√≥n Promedio por Rama de Actividad\", fontsize=16)\n",
    "plt.xlabel(\"Remuneraci√≥n Promedio (ARS)\")\n",
    "plt.ylabel(\"Rama de Actividad\")\n",
    "plt.tight_layout()\n",
    "plt.grid(axis=\"x\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1189eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la remuneraci√≥n promedio mensual para todas las ramas\n",
    "df_prom_mensual = df_rem_long.groupby(\"Fecha\")[\"Remuneracion\"].mean().reset_index()\n",
    "\n",
    "# Crear gr√°fico de dispersi√≥n\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_prom_mensual[\"Fecha\"], df_prom_mensual[\"Remuneracion\"], alpha=0.7, edgecolor='k')\n",
    "plt.title(\"Evoluci√≥n de la Remuneraci√≥n Promedio Mensual\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Remuneraci√≥n (ARS)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Promedio por rama (eje X) y fecha (eje Y), para reducir cantidad de puntos\n",
    "df_avg_rama_fecha = df_rem_long.groupby([\"Rama_Actividad\", \"Fecha\"])[\"Remuneracion\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(\n",
    "    data=df_avg_rama_fecha,\n",
    "    x=\"Fecha\",\n",
    "    y=\"Remuneracion\",\n",
    "    hue=\"Rama_Actividad\",\n",
    "    legend=False,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title(\"Remuneraciones por Rama de Actividad en el Tiempo\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Remuneraci√≥n (ARS)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio mensual para todas las ramas\n",
    "df_prom_mensual = df_rem_long.groupby(\"Fecha\")[\"Remuneracion\"].mean().reset_index()\n",
    "\n",
    "# Gr√°fico de dispersi√≥n con escala logar√≠tmica\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_prom_mensual[\"Fecha\"], df_prom_mensual[\"Remuneracion\"], alpha=0.7, edgecolor='k')\n",
    "plt.yscale('log')  # Escala logar√≠tmica\n",
    "plt.title(\"Evoluci√≥n de la Remuneraci√≥n Promedio Mensual (Escala Logar√≠tmica)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Remuneraci√≥n (ARS, log scale)\")\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio por rama y fecha\n",
    "df_avg_rama_fecha = df_rem_long.groupby([\"Rama_Actividad\", \"Fecha\"])[\"Remuneracion\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(\n",
    "    data=df_avg_rama_fecha,\n",
    "    x=\"Fecha\",\n",
    "    y=\"Remuneracion\",\n",
    "    hue=\"Rama_Actividad\",\n",
    "    legend=False,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.yscale('log')  # Escala logar√≠tmica\n",
    "plt.title(\"Remuneraciones por Rama de Actividad en el Tiempo (Escala Logar√≠tmica)\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Remuneraci√≥n (ARS, log scale)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde03575",
   "metadata": {},
   "source": [
    "### Implementaci√≥n del escalado para atenuar efecto de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Crear una copia del dataframe original limpio\n",
    "df_scaled = df_rem_long.copy()\n",
    "\n",
    "# Inicializar el escalador robusto\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Aplicar el escalador sobre la columna 'Remuneracion' y crear una nueva columna\n",
    "df_scaled[\"Remuneracion_Escalada\"] = scaler.fit_transform(df_scaled[[\"Remuneracion\"]])\n",
    "\n",
    "# Ver un resumen para asegurarte que funcion√≥\n",
    "print(df_scaled[[\"Remuneracion\", \"Remuneracion_Escalada\"]].describe())\n",
    "\n",
    "# Visualizar c√≥mo se comporta despu√©s del escalado\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_scaled[\"Remuneracion_Escalada\"], bins=50, kde=True)\n",
    "plt.title(\"Distribuci√≥n de Remuneraci√≥n Escalada (RobustScaler)\")\n",
    "plt.xlabel(\"Remuneraci√≥n Escalada\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc1371",
   "metadata": {},
   "source": [
    "### Incorporar Dataset de IPC Patagonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el Dataframe para la base de datos de la variacion de precios\n",
    "archivo_ipc = os.path.join(\"..\", \"data\", \"raw\", \"17_1_04_IPC_variaciones_interanuales_segun_divisiones_de_la_canasta_categorias_bienes_y_servicios._Patagonia.xlsx\")\n",
    "df_precios = pd.read_excel(archivo_ipc)\n",
    "df_precios.head()\n",
    "\n",
    "##ver nombre de las columnas\n",
    "print(df_precios.columns.tolist())\n",
    "\n",
    "# Renombrar la primera columna\n",
    "df_precios = df_precios.rename(columns={'Unnamed: 0': 'Categoria'})\n",
    "\n",
    "# Obtener los nombres de columnas actuales\n",
    "cols = df_precios.columns.tolist()\n",
    "\n",
    "# Encontrar el √≠ndice de 'Unnamed: 1'\n",
    "idx_fecha = cols.index('Unnamed: 1')\n",
    "\n",
    "# Generar nuevos nombres para las columnas de fechas\n",
    "nuevos_nombres = {}\n",
    "for i, col in enumerate(cols[idx_fecha:], start=0):\n",
    "    # Asignar nombres de fecha a partir de '2017-12'\n",
    "    fecha = pd.to_datetime('2017-12') + pd.DateOffset(months=i)\n",
    "    nuevos_nombres[col] = fecha.strftime('%Y-%m')\n",
    "\n",
    "# Renombrar las columnas en el DataFrame\n",
    "df_precios = df_precios.rename(columns=nuevos_nombres)\n",
    "\n",
    "print(df_precios.columns.tolist())\n",
    "\n",
    "# Detectar valores nulos en df_precios\n",
    "print(\"Cantidad de valores nulos por columna en df_precios:\")\n",
    "print(df_precios.isnull().sum())\n",
    "\n",
    "# Detectar filas duplicadas en df_precios\n",
    "duplicados_precios = df_precios.duplicated()\n",
    "print(f\"\\nCantidad de filas duplicadas en df_precios: {duplicados_precios.sum()}\")\n",
    "\n",
    "print(\"Cantidad de filas en df_precios:\", len(df_precios))\n",
    "\n",
    "# Verificar columnas\n",
    "print(df_precios.columns.tolist())\n",
    "\n",
    "# Renombrar la primera columna\n",
    "columna_original = df_precios.columns[0]\n",
    "df_precios.rename(columns={columna_original: \"Categoria\"}, inplace=True)\n",
    "\n",
    "print(df_precios['Categoria'].unique())\n",
    "\n",
    "# Filtrar las filas √∫tiles: desde 'Nivel general' hasta 'Servicios'\n",
    "start_idx = df_precios[df_precios['Categoria'] == 'Nivel general'].index[0]\n",
    "end_idx = df_precios[df_precios['Categoria'] == 'Servicios'].index[0]\n",
    "df_precios_limpio = df_precios.loc[start_idx:end_idx].reset_index(drop=True)\n",
    "\n",
    "# Ver los primeros datos para asegurarte\n",
    "print(df_precios_limpio.head())\n",
    "\n",
    "# Contar los nulos por columna\n",
    "nulos_por_columna = df_precios_limpio.isna().sum()\n",
    "\n",
    "# Contar nulos totales\n",
    "total_nulos = df_precios_limpio.isna().sum().sum()\n",
    "\n",
    "print(\"Nulos por columna:\\n\", nulos_por_columna)\n",
    "print(\"\\nTotal de nulos:\", total_nulos)\n",
    "\n",
    "df_precios_limpio = df_precios_limpio.dropna(axis=1, how='all')\n",
    "df_precios_limpio.head(22)\n",
    "\n",
    "df_precios_limpio = df_precios_limpio.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "print(df_precios_limpio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precios_limpio.head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135aac9",
   "metadata": {},
   "source": [
    "### Verificar tipo de datos y convertir a formato largo para poder integrar con los otros df apropiadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11425210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precios_limpio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68be4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear una copia del DataFrame original limpio\n",
    "df_precios_clean = df_precios_limpio.copy()\n",
    "\n",
    "# 2. Seleccionar solo las columnas de fecha (excluyendo 'Categoria')\n",
    "columnas_fecha = df_precios_clean.columns.drop(\"Categoria\")\n",
    "\n",
    "# 3. Limpiar cada celda: quitar espacios, reemplazar coma por punto, eliminar s√≠mbolos no num√©ricos\n",
    "for col in columnas_fecha:\n",
    "    df_precios_clean[col] = (\n",
    "        df_precios_clean[col]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \".\", regex=False)\n",
    "        .str.replace(r\"[^\\d\\.]\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "# 4. Convertir todas las columnas de fecha a float\n",
    "df_precios_clean[columnas_fecha] = df_precios_clean[columnas_fecha].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 5. Verificar cu√°ntos valores NaN hay por columna (opcional)\n",
    "print(\"Valores nulos por columna luego de limpieza:\")\n",
    "print(df_precios_clean[columnas_fecha].isna().sum())\n",
    "\n",
    "# 6. Pasar a formato largo\n",
    "df_precios_long = df_precios_clean.melt(\n",
    "    id_vars=\"Categoria\",\n",
    "    var_name=\"Fecha\",\n",
    "    value_name=\"IPC_Variacion\"\n",
    ")\n",
    "\n",
    "# 7. Convertir columna Fecha a datetime\n",
    "df_precios_long[\"Fecha\"] = pd.to_datetime(df_precios_long[\"Fecha\"], format=\"%Y-%m\")\n",
    "\n",
    "# 8. Eliminar valores nulos (si quedaron)\n",
    "df_precios_long = df_precios_long.dropna(subset=[\"IPC_Variacion\"]).reset_index(drop=True)\n",
    "\n",
    "# 9. Verificar el resultado\n",
    "print(df_precios_long.head())\n",
    "print(f\"Total de registros: {len(df_precios_long)}\")\n",
    "print(f\"Rango de fechas: {df_precios_long['Fecha'].min().date()} ‚Üí {df_precios_long['Fecha'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b339997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_precios_long.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd433d1c",
   "metadata": {},
   "source": [
    "### Verificar outliers para definir su tratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0554dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas generales\n",
    "print(df_precios_long[\"IPC_Variacion\"].describe())\n",
    "\n",
    "# Boxplot general\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=\"IPC_Variacion\", data=df_precios_long)\n",
    "plt.title(\"Distribuci√≥n general del IPC interanual\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot por categor√≠a\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(data=df_precios_long, y=\"Categoria\", x=\"IPC_Variacion\")\n",
    "plt.title(\"Distribuci√≥n del IPC interanual por Categor√≠a\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detectar outliers por percentil 99\n",
    "umbral_99 = df_precios_long[\"IPC_Variacion\"].quantile(0.99)\n",
    "outliers_ipc = df_precios_long[df_precios_long[\"IPC_Variacion\"] > umbral_99]\n",
    "print(f\"\\nUmbral (percentil 99): {umbral_99:.2f}\")\n",
    "print(f\"Outliers detectados: {len(outliers_ipc)} registros\")\n",
    "\n",
    "# Mostrar los top 5 valores m√°s altos\n",
    "print(\"\\nTop 5 IPC m√°s altos:\")\n",
    "print(outliers_ipc.sort_values(by=\"IPC_Variacion\", ascending=False).head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ffbc55",
   "metadata": {},
   "source": [
    "### Tratamiento de Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1766a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# 1. Crear una copia para no modificar el original\n",
    "df_ipc_suavizado = df_precios_long.copy()\n",
    "\n",
    "# 2. Inicializar el escalador\n",
    "scaler_ipc = RobustScaler()\n",
    "\n",
    "# 3. Aplicar escalado y guardar en nueva columna\n",
    "df_ipc_suavizado[\"IPC_Escalado\"] = scaler_ipc.fit_transform(df_ipc_suavizado[[\"IPC_Variacion\"]])\n",
    "\n",
    "# 4. Verificar resultado\n",
    "print(df_ipc_suavizado[[\"IPC_Variacion\", \"IPC_Escalado\"]].describe())\n",
    "\n",
    "# 5. Opcional: visualizar distribuci√≥n escalada\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_ipc_suavizado[\"IPC_Escalado\"], bins=50, kde=True)\n",
    "plt.title(\"Distribuci√≥n de IPC Escalado (RobustScaler)\")\n",
    "plt.xlabel(\"IPC Escalado\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c9d72",
   "metadata": {},
   "source": [
    "## Incorporar Dataset de tarjetas BCRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7085d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta relativa o absoluta del archivo \n",
    "archivo_tarjetas = os.path.join(\"..\", \"data\", \"raw\", \"Series_anual_2023_20240507.xlsx\")\n",
    "\n",
    "# Leer la hoja \"Pagos minoristas\"\n",
    "df_tarjetas = pd.read_excel(archivo_tarjetas, sheet_name=\"Pagos minoristas\")\n",
    "\n",
    "# Renombrar columnas √∫tiles para mayor claridad\n",
    "df_tarjetas_credito = df_tarjetas.rename(columns={\n",
    "    'Unnamed: 0': 'Fecha',\n",
    "    'Tarjetas de cr√©dito': 'Cantidad',\n",
    "    'Unnamed: 35': 'Monto_nominal',\n",
    "    'Unnamed: 36': 'Monto_constante'\n",
    "})[['Fecha', 'Cantidad', 'Monto_nominal', 'Monto_constante']]\n",
    "\n",
    "print(df_tarjetas_credito.head())\n",
    "print(df_tarjetas_credito.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bfe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame limpio\n",
    "df_tarjetas_limpio = df_tarjetas_credito.iloc[1:].copy()  # eliminar fila de t√≠tulos\n",
    "\n",
    "# Renombrar columnas\n",
    "df_tarjetas_limpio.columns = [\"Fecha\", \"Cantidad\", \"Monto_nominal\", \"Monto_constante\"]\n",
    "\n",
    "# Convertir fechas y datos num√©ricos\n",
    "df_tarjetas_limpio[\"Fecha\"] = pd.to_datetime(df_tarjetas_limpio[\"Fecha\"])\n",
    "df_tarjetas_limpio[\"Cantidad\"] = pd.to_numeric(df_tarjetas_limpio[\"Cantidad\"], errors=\"coerce\")\n",
    "df_tarjetas_limpio[\"Monto_nominal\"] = pd.to_numeric(df_tarjetas_limpio[\"Monto_nominal\"], errors=\"coerce\")\n",
    "df_tarjetas_limpio[\"Monto_constante\"] = pd.to_numeric(df_tarjetas_limpio[\"Monto_constante\"], errors=\"coerce\")\n",
    "df_tarjetas_limpio[\"Fecha\"] = pd.to_datetime(df_tarjetas_limpio[\"Fecha\"])\n",
    "df_tarjetas_limpio[\"Fecha\"] = df_tarjetas_limpio[\"Fecha\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# Verificar estructura\n",
    "print(df_tarjetas_limpio.head())\n",
    "print(df_tarjetas_limpio.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3c0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar nulos por columna\n",
    "print(\" Valores nulos por columna:\")\n",
    "print(df_tarjetas_limpio.isnull().sum())\n",
    "\n",
    "# Verificar si hay filas duplicadas\n",
    "duplicados = df_tarjetas_limpio.duplicated()\n",
    "print(f\"\\n Cantidad de filas duplicadas: {duplicados.sum()}\")\n",
    "\n",
    "# Si quer√©s ver cu√°les son:\n",
    "if duplicados.sum() > 0:\n",
    "    print(\"\\n Filas duplicadas:\")\n",
    "    print(df_tarjetas_limpio[duplicados])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4690286",
   "metadata": {},
   "source": [
    "### Verificaci√≥n de outliers para determinar su tratamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d043750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la columna 'Fecha' est√© en formato datetime\n",
    "df_tarjetas_limpio['Fecha'] = pd.to_datetime(df_tarjetas_limpio['Fecha'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9877ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por fecha (por si no lo estuviera)\n",
    "df_tarjetas_limpio = df_tarjetas_limpio.sort_values(by='Fecha')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8854465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gr√°fico\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(df_tarjetas_limpio['Fecha'], df_tarjetas_limpio['Monto_constante'] / 1e9)  # Escalado en miles de millones\n",
    "\n",
    "plt.title('üìà Evoluci√≥n del Consumo con Tarjeta (ajustado por inflaci√≥n)', fontsize=14)\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Monto constante (miles de millones de ARS)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f23af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe general\n",
    "print(df_tarjetas_limpio['Monto_constante'].describe())\n",
    "\n",
    "# Percentil 99\n",
    "percentil_99 = df_tarjetas_limpio['Monto_constante'].quantile(0.99)\n",
    "outliers = df_tarjetas_limpio[df_tarjetas_limpio['Monto_constante'] > percentil_99]\n",
    "\n",
    "print(f\"\\n Umbral del percentil 99: {percentil_99:,.2f}\")\n",
    "print(f\" Registros considerados outliers: {len(outliers)}\")\n",
    "\n",
    "# Mostrar top 5 outliers\n",
    "print(\"\\n Top 5 montos m√°s altos:\")\n",
    "print(outliers.sort_values(by=\"Monto_constante\", ascending=False).head())\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x=df_tarjetas_limpio['Monto_constante'])\n",
    "plt.title('Distribuci√≥n de Monto Constante (Outliers a la derecha)')\n",
    "plt.xlabel('Monto Constante (ARS)')\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Instanciar el scaler\n",
    "scaler_tarjetas = RobustScaler()\n",
    "\n",
    "# Aplicar el escalado solo a la columna 'Monto_constante' y guardar en nueva columna\n",
    "df_tarjetas_limpio['Monto_Escalado'] = scaler_tarjetas.fit_transform(\n",
    "    df_tarjetas_limpio[['Monto_constante']]\n",
    ")\n",
    "\n",
    "# Verificar resultados\n",
    "print(df_tarjetas_limpio[['Fecha', 'Monto_constante', 'Monto_Escalado']].head())\n",
    "\n",
    "# Estad√≠sticas para revisar c√≥mo qued√≥\n",
    "print(\"\\nResumen estad√≠stico del Monto escalado:\")\n",
    "print(df_tarjetas_limpio['Monto_Escalado'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c5241",
   "metadata": {},
   "source": [
    "## Integraci√≥n de los Dataframes para poder avanzar en el modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517bbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificar df_scaled con df_ipc_suavizado\n",
    "df_merged = pd.merge(df_scaled, df_ipc_suavizado, on=\"Fecha\", how=\"inner\")\n",
    "\n",
    "# Unificar el resultado anterior con df_tarjetas_limpio\n",
    "df_final = pd.merge(df_merged, df_tarjetas_limpio, on=\"Fecha\", how=\"inner\")\n",
    "\n",
    "# Verificar la forma final\n",
    "print(\"Dimensiones del DataFrame unificado:\", df_final.shape)\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['A√±o'] = df_final['Fecha'].dt.year\n",
    "resumen_anual = df_final.groupby('A√±o').agg({\n",
    "    'Remuneracion': 'mean',\n",
    "    'IPC_Variacion': 'mean',\n",
    "    'Monto_constante': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "print(resumen_anual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionamos solo columnas num√©ricas √∫tiles\n",
    "variables_numericas = df_final[[\n",
    "    'Remuneracion', 'Remuneracion_Escalada',\n",
    "    'IPC_Variacion', 'IPC_Escalado',\n",
    "    'Cantidad', 'Monto_nominal', 'Monto_constante', 'Monto_Escalado'\n",
    "]]\n",
    "\n",
    "# Calcular la matriz de correlaci√≥n\n",
    "corr_matrix = variables_numericas.corr()\n",
    "\n",
    "# Visualizar la matriz\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\" Matriz de correlaci√≥n entre variables econ√≥micas\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e045d0a",
   "metadata": {},
   "source": [
    "# Modelado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b43b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -------------------\n",
    "# Variables base\n",
    "# -------------------\n",
    "features_A = ['Remuneracion_Escalada', 'IPC_Escalado']\n",
    "features_B = features_A + ['Cantidad']\n",
    "features_C = features_B + ['Rama_Actividad', 'Categoria']  # para dummies\n",
    "\n",
    "target = 'Monto_constante'\n",
    "\n",
    "# -------------------\n",
    "# A. Modelo base\n",
    "# -------------------\n",
    "X_A = df_final[features_A]\n",
    "y = df_final[target]\n",
    "\n",
    "X_train_A, X_test_A, y_train, y_test = train_test_split(X_A, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo_A = LinearRegression()\n",
    "modelo_A.fit(X_train_A, y_train)\n",
    "y_pred_A = modelo_A.predict(X_test_A)\n",
    "\n",
    "print(\" Modelo A - Base\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_A))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred_A))\n",
    "print()\n",
    "\n",
    "# -------------------\n",
    "# B. Modelo mejorado\n",
    "# -------------------\n",
    "X_B = df_final[features_B]\n",
    "X_train_B, X_test_B, _, _ = train_test_split(X_B, y, test_size=0.2, random_state=42)\n",
    "\n",
    "modelo_B = LinearRegression()\n",
    "modelo_B.fit(X_train_B, y_train)\n",
    "y_pred_B = modelo_B.predict(X_test_B)\n",
    "\n",
    "print(\" Modelo B - +Cantidad\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_B))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred_B))\n",
    "print()\n",
    "\n",
    "# -------------------\n",
    "# C. Modelo completo con dummies\n",
    "# -------------------\n",
    "X_C = df_final[features_C]\n",
    "\n",
    "# Preprocesamiento de variables categ√≥ricas\n",
    "categorical_features = ['Rama_Actividad', 'Categoria']\n",
    "numeric_features = ['Remuneracion_Escalada', 'IPC_Escalado', 'Cantidad']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "pipeline_C = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "X_train_C, X_test_C, _, _ = train_test_split(X_C, y, test_size=0.2, random_state=42)\n",
    "pipeline_C.fit(X_train_C, y_train)\n",
    "y_pred_C = pipeline_C.predict(X_test_C)\n",
    "\n",
    "print(\" Modelo C - +Categor√≠as\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_C))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred_C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb21be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras \n",
    "X = df_final[['Remuneracion_Escalada', 'IPC_Escalado']]\n",
    "\n",
    "# Variable objetivo\n",
    "y = df_final['Monto_constante']\n",
    "\n",
    "# dividir el dataset en entrenamiento y prueba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo de regresi√≥n lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "#evaluar el modelo\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Error cuadr√°tico medio (MSE): {mse:.2f}\")\n",
    "print(f\"R¬≤ (explicaci√≥n de la varianza): {r2:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec482296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetir para  validar:\n",
    "y_pred_B = modelo_B.predict(X_test_B)\n",
    "\n",
    "# Mostrar algunas predicciones vs valores reales\n",
    "resultados = pd.DataFrame({\n",
    "    'Real': y_test.values,\n",
    "    'Predicho': y_pred_B\n",
    "})\n",
    "print(resultados.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una muestra futura\n",
    "nueva_muestra = pd.DataFrame({\n",
    "    'Remuneracion_Escalada': [0.2],\n",
    "    'IPC_Escalado': [0.2],\n",
    "    'Cantidad': [df_final['Cantidad'].mean()]  # promedio actual\n",
    "})\n",
    "\n",
    "# Predecir\n",
    "prediccion_futura = modelo_B.predict(nueva_muestra)\n",
    "\n",
    "print(f\"Predicci√≥n de monto constante en tarjeta: ${prediccion_futura[0]:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a9fbe",
   "metadata": {},
   "source": [
    "## **Conclusiones Finales:**\n",
    "\n",
    "El objetivo fue analizar si la evoluci√≥n de los salarios y el √≠ndice de precios al consumidor (IPC) pueden explicar y predecir el comportamiento del endeudamiento (medido a trav√©s del consumo con tarjeta de cr√©dito), considerando el contexto econ√≥mico argentino.\n",
    "\n",
    "*Principales Hallazgos del An√°lisis*\n",
    "- Se observaron **fuertes incrementos en el IPC** desde 2022, con picos que podr√≠an sesgar el modelo si no se suavizan.\n",
    "- Las **remuneraciones tambi√©n aumentaron**, pero en muchos casos no lograron seguir el ritmo de la inflaci√≥n.\n",
    "- El **consumo con tarjeta** mostr√≥ comportamientos contextuales, como un pico en octubre 2023 (coincidente con elecciones).\n",
    "- Se realiz√≥ un tratamiento robusto de outliers con **\"RobustScaler\"**, evitando la eliminaci√≥n de informaci√≥n relevante.\n",
    "\n",
    "*Sobre el Modelo*\n",
    "- Se probaron tres modelos de regresi√≥n lineal.\n",
    "- El modelo que incorpor√≥ \"Remuneraci√≥n_Escalada\", \"IPC_Escalado\" y \"Cantidad de tarjetas\" (**Modelo B**) fue el m√°s preciso:\n",
    "  - **MSE**: 2.13e+19\n",
    "  - **R¬≤**: 0.7759\n",
    "- Este modelo fue utilizado para hacer predicciones sobre el monto consumido con tarjetas.\n",
    "\n",
    "*Conclusi√≥n General*\n",
    "El modelo demostr√≥ que existe una **relaci√≥n significativa entre salarios, precios y endeudamiento**. Aunque no se logr√≥ un 100% de precisi√≥n, se obtuvo un modelo con buen poder explicativo. Se confirma que **el endeudamiento tiende a crecer cuando la inflaci√≥n supera a los salarios**, obligando a las personas a financiar gastos cotidianos.\n",
    "\n",
    "*Posibles Mejoras Futuras*\n",
    "- Incorporar variables regionales si se consigue un dataset exclusivo para la Patagonia.\n",
    "- Probar modelos m√°s complejos como **Random Forest Regressor** o **XGBoost**.\n",
    "- Extender la predicci√≥n al mediano plazo (forecasting con series temporales).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
